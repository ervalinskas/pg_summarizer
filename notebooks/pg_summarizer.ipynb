{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "import re\n",
    "import tiktoken\n",
    "import concurrent\n",
    "import ast\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from openai import OpenAI\n",
    "from csv import reader, writer\n",
    "from functools import lru_cache\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy import spatial\n",
    "from collections import namedtuple\n",
    "from termcolor import colored\n",
    "from IPython.display import Markdown\n",
    "\n",
    "URL = \"https://paulgraham.com/{}\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "LIBRARY = \"../data/essays.csv\"\n",
    "client = OpenAI()\n",
    "Essay = namedtuple(\"Essay\", [\"title\", \"url\", \"embedding\", \"text\"])\n",
    "\n",
    "\n",
    "def is_library_empty(library):\n",
    "    try:\n",
    "        with open(library, \"r\", newline=\"\") as f_object:\n",
    "            reader_object = reader(f_object)\n",
    "            first_data_row = next(reader_object, None)\n",
    "            return first_data_row is None\n",
    "    except FileNotFoundError:\n",
    "        return True\n",
    "\n",
    "\n",
    "def initiate_library(library):\n",
    "    filename = Path(library)\n",
    "    filename.parent.mkdir(exist_ok=True)\n",
    "    with open(filename, \"w\"):\n",
    "        pass\n",
    "\n",
    "\n",
    "@lru_cache\n",
    "def get_page_content(url):\n",
    "    page = requests.get(URL.format(url))\n",
    "    return BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def get_embedding_response(text):\n",
    "    response = client.embeddings.create(input=text, model=EMBEDDING_MODEL)\n",
    "    return response\n",
    "\n",
    "\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"?\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "\n",
    "def get_essay_urls():\n",
    "    soup = get_page_content(url=\"articles.html\")\n",
    "    links = soup.findAll(\"a\")\n",
    "\n",
    "    essay_urls = {\n",
    "        link[\"href\"]\n",
    "        for link in links\n",
    "        if (link[\"href\"].endswith(\".html\"))\n",
    "        and link[\"href\"] not in {\"index.html\", \"rss.html\"}\n",
    "    }\n",
    "    return essay_urls\n",
    "\n",
    "\n",
    "def get_essay_object(url):\n",
    "    soup = get_page_content(url)\n",
    "    raw_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    raw_text_without_notes = raw_text.split(\"Notes\")[0]\n",
    "    raw_text_without_thankyous = raw_text_without_notes.split(\"Thanks\")[0]\n",
    "    clean_text = re.sub(r\"\\[\\n\\d+\\n\\]\", \"\", raw_text_without_thankyous)\n",
    "    result = {\n",
    "        \"title\": clean_text.split(\"\\n\")[0],\n",
    "        \"date\": clean_text.split(\"\\n\")[1],\n",
    "        \"essay_text\": \"\".join(clean_text.split(\"\\n\")[2:]),\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_essays(urls, library):\n",
    "    if is_library_empty(library):\n",
    "        initiate_library(library)\n",
    "        for url in tqdm(urls, position=0):\n",
    "            essay_object = get_essay_object(url)\n",
    "\n",
    "            embedding_response = get_embedding_response(essay_object[\"title\"])\n",
    "\n",
    "            file_reference = [\n",
    "                essay_object[\"title\"],\n",
    "                URL.format(url),\n",
    "                embedding_response.data[0].embedding,\n",
    "                essay_object[\"essay_text\"],\n",
    "            ]\n",
    "\n",
    "            with open(library, \"a\") as f_object:\n",
    "                writer_object = writer(f_object)\n",
    "                writer_object.writerow(file_reference)\n",
    "                f_object.close()\n",
    "\n",
    "\n",
    "def read_essay_library(library):\n",
    "    essay_objects = []\n",
    "    with open(library, \"r\", newline=\"\\n\") as f_object:\n",
    "        reader_object = reader(f_object)\n",
    "        for row in reader_object:\n",
    "            essay = Essay(\n",
    "                title=row[0],\n",
    "                url=row[1],\n",
    "                embedding=ast.literal_eval(row[2]),\n",
    "                text=row[3],\n",
    "            )\n",
    "            essay_objects.append(essay)\n",
    "    return essay_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essay_urls = get_essay_urls()\n",
    "# get_essays(essay_urls, LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_library = read_essay_library(LIBRARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_essays_ranked_by_relatedness(\n",
    "    query,\n",
    "    top_n=5,\n",
    "    similarity_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "):\n",
    "    query_embedding_response = get_embedding_response(query)\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "    essays_and_relatedness = [\n",
    "        (essay, similarity_fn(query_embedding, essay.embedding))\n",
    "        for essay in essay_library\n",
    "    ]\n",
    "    essays_and_relatedness.sort(key=lambda x: x[1], reverse=True)\n",
    "    essays, relatedness = zip(*essays_and_relatedness)\n",
    "    return essays[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_essay_text(result):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    chunks = create_chunks(result, 1800, tokenizer)\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "    return text_chunks\n",
    "\n",
    "\n",
    "def summarize_chunk(template_prompt, content):\n",
    "    full_prompt = template_prompt + content\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": full_prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def read_and_summarize(title):\n",
    "    results = \"\"\n",
    "    essay_to_summarize = [essay.text for essay in essay_library if essay.title == title][0]\n",
    "    text_chunks = chunk_essay_text(essay_to_summarize)\n",
    "\n",
    "    summary_prompt = \"\"\"Summarize this text from Paul Grahams esssay.\\n\\nContent:\"\"\"\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(\n",
    "        max_workers=len(text_chunks)\n",
    "    ) as executor:\n",
    "        futures = [\n",
    "            executor.submit(summarize_chunk, text_chunk, summary_prompt)\n",
    "            for text_chunk in text_chunks\n",
    "        ]\n",
    "        with tqdm(total=len(text_chunks)) as pbar:\n",
    "            for _ in concurrent.futures.as_completed(futures):\n",
    "                pbar.update(1)\n",
    "        for future in futures:\n",
    "            data = future.result()\n",
    "            results += data\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Write a final summary for the requested Paul Graham essay from small summaries extracted from chunks of the same essay.\n",
    "                            Chunked summaries:\\n{results}\\nSummary:\\n\"\"\",\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model, messages=messages, tools=tools\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self):\n",
    "        role_to_color = {\n",
    "            \"system\": \"red\",\n",
    "            \"user\": \"green\",\n",
    "            \"assistant\": \"blue\",\n",
    "            \"function\": \"magenta\",\n",
    "        }\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                colored(\n",
    "                    f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                    role_to_color[message[\"role\"]],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_essays_ranked_by_relatedness\",\n",
    "            \"description\": \"Use this function to get Paul Graham essays to answer user questions.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"User query in JSON.\"},\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_and_summarize\",\n",
    "            \"description\": \"\"\"Use this function to whole Paul Graham essay and provide summary for user.\n",
    "                        You should NEVER call this function before get_essays_ranked_by_relatedness has been called in the conversation.\"\"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"title\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Title of the requested Paul Graham essay to be summarized\",\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_pg_essay_function(messages, full_message):\n",
    "    if (\n",
    "        full_message.message.tool_calls[0].function.name\n",
    "        == \"get_essays_ranked_by_relatedness\"\n",
    "    ):\n",
    "        try:\n",
    "            parsed_arguments = json.loads(\n",
    "                full_message.message.tool_calls[0].function.arguments\n",
    "            )\n",
    "            print(\"Getting most relevant Paul Graham essays\")\n",
    "            results = get_essays_ranked_by_relatedness(parsed_arguments[\"query\"])\n",
    "        except Exception as e:\n",
    "            print(parsed_arguments)\n",
    "            print(\"Function execution failed\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        \n",
    "        str_result = \"\"\n",
    "        for index, essay in enumerate(results, start=1):\n",
    "            str_result += f\"{index}. {essay.title}\\n\"\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": full_message.message.role,\n",
    "                \"name\": full_message.message.tool_calls[0].function.name,\n",
    "                \"content\": str_result,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            print(\"Got search results, summarizing content\")\n",
    "            response = chat_completion_request(messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            raise Exception(\"Function chat request failed\")\n",
    "\n",
    "    elif full_message.message.tool_calls[0].function.name == \"read_and_summarize\":\n",
    "        parsed_output = json.loads(\n",
    "            full_message.message.tool_calls[0].function.arguments\n",
    "        )\n",
    "        print(\"Finding and reading essay\")\n",
    "        summary = read_and_summarize(parsed_output[\"title\"])\n",
    "        return summary\n",
    "    else:\n",
    "        raise Exception(\"Function does not exist and can't be called\")\n",
    "\n",
    "\n",
    "def chat_completion_with_tool_execution(messages, tools=None):\n",
    "    response = chat_completion_request(messages, tools)\n",
    "    full_message = response.choices[0]\n",
    "    if full_message.finish_reason == \"tool_calls\":\n",
    "        print(\"Function generation requested, calling function\")\n",
    "        return call_pg_essay_function(messages, full_message)\n",
    "    else:\n",
    "        print(\"Function not required, responding to user.\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conversation with system message\n",
    "system_message = \"\"\"You are a helpful assistant that pulls relevant Paul Graham essays when needed to answer user questions.\n",
    "                    You always provide essay title and url so that user could decide which essay to read to answer their question.\n",
    "                    Begin!\"\"\"\n",
    "conversation = Conversation()\n",
    "conversation.add_message(\"system\", system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Getting most relevant Paul Graham essays\n",
      "Got search results, summarizing content\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are the top 5 Paul Graham essays related to starting a startup:\n",
       "\n",
       "1. Essay: How to Start a Startup\n",
       "   URL: http://www.paulgraham.com/startuplessons.html\n",
       "\n",
       "2. Essay: Ideas for Startups\n",
       "   URL: http://www.paulgraham.com/startupideas.html\n",
       "\n",
       "3. Essay: How to Fund a Startup\n",
       "   URL: http://www.paulgraham.com/startupfunding.html\n",
       "\n",
       "4. Essay: A Student's Guide to Startups\n",
       "   URL: http://www.paulgraham.com/hs.html\n",
       "\n",
       "5. Essay: The Future of Web Startups\n",
       "   URL: http://www.paulgraham.com/webstartups.html\n",
       "\n",
       "Feel free to click on the URLs to read any of these essays that you find most relevant to your question!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a user message\n",
    "conversation.add_message(\"user\", \"Hi, what advice does Paul Graham like to give on the topic of starting a startup?\")\n",
    "chat_response = chat_completion_with_tool_execution(conversation.conversation_history, tools)\n",
    "assistant_message = chat_response.choices[0].message.content\n",
    "conversation.add_message(\"assistant\", assistant_message)\n",
    "display(Markdown(assistant_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Finding and reading essay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In this essay, Paul Graham discusses the key factors for creating a successful startup. He emphasizes the importance of having good people, creating a product that customers actually want, and minimizing expenses. Graham argues that a brilliant idea is not necessary to start a successful startup, as long as the product or service offers better technology than what is currently available. He also highlights the importance of addressing intellectual property issues and being cautious when approaching investors. Graham advises startups to focus on niche markets, target smaller customers, and be cautious with spending. He emphasizes the need to understand the business and put users first in order to succeed. Graham also discusses the challenges and considerations related to age when starting a startup. Ultimately, he suggests that starting a startup can be a way to solve the money problem and offers advice on how to approach it: build something users love and spend less than you make."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation.add_message(\"user\", \"Could you please read and summarize the first essay?\")\n",
    "updated_response = chat_completion_with_tool_execution(conversation.conversation_history, tools)\n",
    "display(Markdown(updated_response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
